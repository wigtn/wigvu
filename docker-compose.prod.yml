# Production Docker Compose for GCP Compute Engine
# Usage: docker compose -f docker-compose.prod.yml up -d

services:
  # Frontend - Next.js Web Application
  web:
    build:
      context: ./apps/web
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=production
      - API_URL=http://api:4000
    depends_on:
      api:
        condition: service_healthy
    restart: always
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:3000"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Backend API Service - NestJS API Gateway
  api:
    build:
      context: ./apps/api
      dockerfile: Dockerfile
    ports:
      - "4000:4000"
    environment:
      - NODE_ENV=production
      - PORT=4000
      - CORS_ORIGIN=${CORS_ORIGIN:-http://localhost:3000}
      - YOUTUBE_API_KEY=${YOUTUBE_API_KEY}
      - AI_SERVICE_URL=http://ai:5000
      - INTERNAL_API_KEY=${INTERNAL_API_KEY}
      - STT_MAX_DURATION_MINUTES=${STT_MAX_DURATION_MINUTES:-120}
      - MAX_VIDEO_DURATION_MINUTES=${MAX_VIDEO_DURATION_MINUTES:-25}
      - RATE_LIMIT_WINDOW_MS=${RATE_LIMIT_WINDOW_MS:-60000}
      - RATE_LIMIT_MAX=${RATE_LIMIT_MAX:-60}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    depends_on:
      ai:
        condition: service_healthy
    restart: always
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:4000/api/v1/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # AI Backend Service - LLM Analysis & STT Proxy
  ai:
    build:
      context: ./apps/ai
      dockerfile: Dockerfile
    ports:
      - "5000:5000"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-4o-mini}
      - INTERNAL_API_KEY=${INTERNAL_API_KEY}
      - STT_API_URL=${STT_API_URL}
      - STT_MAX_DURATION_MINUTES=${STT_MAX_DURATION_MINUTES:-120}
      - MAX_FILE_SIZE_MB=${MAX_FILE_SIZE_MB:-500}
      - RATE_LIMIT_ANALYZE=${RATE_LIMIT_ANALYZE:-30}
      - RATE_LIMIT_STT=${RATE_LIMIT_STT:-10}
      - MAX_CONCURRENT_REQUESTS=${MAX_CONCURRENT_REQUESTS:-10}
      - RETRY_MAX_ATTEMPTS=${RETRY_MAX_ATTEMPTS:-3}
      - RETRY_BASE_DELAY=${RETRY_BASE_DELAY:-1.0}
      - TIMEOUT_ANALYZE=${TIMEOUT_ANALYZE:-30}
      - TIMEOUT_STT=${TIMEOUT_STT:-300}
      - TIMEOUT_HEALTH=${TIMEOUT_HEALTH:-5}
      - MAX_TITLE_LENGTH=${MAX_TITLE_LENGTH:-200}
      - MAX_CHANNEL_LENGTH=${MAX_CHANNEL_LENGTH:-100}
      - MAX_DESCRIPTION_LENGTH=${MAX_DESCRIPTION_LENGTH:-2000}
      - MAX_TRANSCRIPT_LENGTH=${MAX_TRANSCRIPT_LENGTH:-50000}
      - MAX_SEGMENTS_COUNT=${MAX_SEGMENTS_COUNT:-1000}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    restart: always
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Nginx Reverse Proxy (Optional - for production with SSL)
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
    depends_on:
      - web
      - api
    restart: always
    profiles:
      - with-nginx
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
